#!/usr/bin/env python3
"""
Google Colab Training Script for Enhanced BanglaBERT Hate Speech Detection
This script includes Google Drive mounting to save MLflow logs and prevent data loss
"""

import os
import sys
import subprocess
from pathlib import Path

def check_colab_environment():
    """Check if running in Google Colab"""
    try:
        import google.colab
        return True
    except ImportError:
        return False

def mount_google_drive():
    """Mount Google Drive in Colab environment"""
    if not check_colab_environment():
        print("Not running in Google Colab. Skipping Google Drive mounting.")
        return None
    
    try:
        from google.colab import drive
        print("ğŸ”— Mounting Google Drive...")
        drive.mount('/content/drive')
        
        # Create MLflow directory in Google Drive
        drive_mlflow_path = '/content/drive/MyDrive/bangla_bert_mlflow'
        os.makedirs(drive_mlflow_path, exist_ok=True)
        
        # Create symlink for easier access
        if os.path.exists('/content/mlruns'):
            os.remove('/content/mlruns')
        os.symlink(drive_mlflow_path, '/content/mlruns')
        
        print(f"âœ… Google Drive mounted successfully!")
        print(f"ğŸ“ MLflow logs will be saved to: {drive_mlflow_path}")
        return drive_mlflow_path
        
    except Exception as e:
        print(f"âŒ Error mounting Google Drive: {e}")
        print("âš ï¸  Continuing without Google Drive. MLflow logs will be saved locally.")
        return None

def install_dependencies():
    """Install required dependencies"""
    print("ğŸ“¦ Installing dependencies...")
    
    # Install required packages
    packages = [
        'transformers==4.44.2',
        'torch==2.4.0',
        'scikit-learn==1.5.1',
        'pandas==2.2.2',
        'numpy==1.26.4',
        'tqdm==4.66.4',
        'mlflow==2.14.1',
        'emoji==2.12.1'
    ]
    
    for package in packages:
        try:
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
            print(f"âœ… Installed {package}")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Failed to install {package}: {e}")
    
    print("âœ… All dependencies installed successfully!")

def check_gpu():
    """Check if GPU is available"""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"ğŸš€ GPU detected: {gpu_name}")
            return True
        else:
            print("âš ï¸  No GPU detected. Training will be slower.")
            return False
    except ImportError:
        print("âŒ PyTorch not installed. Please install dependencies first.")
        return False

def setup_environment():
    """Setup the training environment"""
    print("ğŸ”§ Setting up environment...")
    
    # Check if we're in Colab
    is_colab = check_colab_environment()
    print(f"ğŸ“ Running in Google Colab: {is_colab}")
    
    # Mount Google Drive if in Colab
    drive_path = mount_google_drive()
    
    # Install dependencies
    install_dependencies()
    
    # Check GPU
    check_gpu()
    
    return is_colab, drive_path

def download_dataset():
    """Download or prepare the dataset"""
    dataset_path = "data/5_BanEmoHate.csv"
    
    if not os.path.exists(dataset_path):
        print("ğŸ“ Dataset not found. Please upload your dataset file.")
        print(f"Expected path: {dataset_path}")
        print("You can upload files using the Colab file browser or by running:")
        print("from google.colab import files")
        print("uploaded = files.upload()")
        return False
    
    print(f"âœ… Dataset found at: {dataset_path}")
    return True

def run_training(author_name="colab_user", **kwargs):
    """Run the enhanced training"""
    print("ğŸš€ Starting enhanced BanglaBERT training...")
    
    # Build command
    cmd = [sys.executable, 'train.py']
    
    # Add arguments
    cmd.extend(['--author_name', author_name])
    cmd.extend(['--dataset_path', 'data/5_BanEmoHate.csv'])
    
    # Default optimized parameters
    default_params = {
        'batch': 32,
        'lr': 2e-5,
        'epochs': 30,
        'max_length': 256,
        'dropout': 0.3,
        'mlflow_experiment_name': 'Bangla_Hate_Speech_Enhanced_Colab'
    }
    
    # Override with user-provided parameters
    default_params.update(kwargs)
    
    # Add parameters to command
    for key, value in default_params.items():
        cmd.extend([f'--{key}', str(value)])
    
    print(f"ğŸ“‹ Training command: {' '.join(cmd)}")
    
    try:
        # Run training
        subprocess.run(cmd, check=True)
        print("âœ… Training completed successfully!")
        
        # Show MLflow logs location
        if os.path.exists('/content/mlruns'):
            print(f"ğŸ“Š MLflow logs saved to: /content/mlruns")
            if check_colab_environment():
                print(f"ğŸ’¾ Also saved to Google Drive: /content/drive/MyDrive/bangla_bert_mlflow")
        
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ Training failed: {e}")
        return False

def show_mlflow_ui():
    """Show MLflow UI instructions"""
    print("\nğŸ“Š MLflow UI Instructions:")
    print("1. To view MLflow experiments, run:")
    print("   !mlflow ui")
    print("2. Click on the generated link (usually http://localhost:5000)")
    print("3. Or use ngrok for external access:")
    print("   !pip install pyngrok")
    print("   from pyngrok import ngrok")
    print("   ngrok.kill()")
    print("   ngrok_tunnel = ngrok.connect(5000)")
    print("   print('MLflow UI:', ngrok_tunnel.public_url)")

def main():
    """Main function for Colab training"""
    print("=" * 60)
    print("ğŸš€ Enhanced BanglaBERT Hate Speech Detection - Google Colab")
    print("=" * 60)
    
    # Setup environment
    is_colab, drive_path = setup_environment()
    
    # Check dataset
    if not download_dataset():
        print("âŒ Please upload the dataset and try again.")
        return
    
    # Show MLflow instructions
    show_mlflow_ui()
    
    # Run training with default parameters
    print("\nğŸ¯ Starting training with optimized parameters...")
    success = run_training(
        author_name="colab_user",
        batch=32,
        lr=2e-5,
        epochs=30,
        max_length=256,
        dropout=0.3
    )
    
    if success:
        print("\nğŸ‰ Training completed successfully!")
        print("ğŸ“Š Check your MLflow logs for detailed results.")
        if is_colab and drive_path:
            print(f"ğŸ’¾ All logs saved to Google Drive: {drive_path}")
    else:
        print("\nâŒ Training failed. Please check the error messages above.")

if __name__ == "__main__":
    main()
